# LokaFlowâ„¢ â€” Full System Architecture

> **Version:** v1.x MVP (current) + V2 roadmap  
> **Owner:** LearnHubPlay BV Â· License: BUSL 1.1  
> **Last updated:** 2026-03-01

---

## 1. Ecosystem Overview

LokaFlow is a family of 10 products sharing a single principle:
**measure AI usage precisely, route it intelligently, make every token count.**

```
LokaFlowâ„¢ Ecosystem
â”‚
â”œâ”€â”€ MEASURE
â”‚   â””â”€â”€ LokaAuditâ„¢      "The number your AI provider doesn't want you to see."
â”‚                        Parse Claude/ChatGPT/Gemini exports â†’ show utilisation %
â”‚
â”œâ”€â”€ ROUTE
â”‚   â”œâ”€â”€ LokaFlow Coreâ„¢  "Right model. Right price. Every time."        â† current repo
â”‚   â”‚                    CLI + REST API + OpenAI-compatible proxy
â”‚   â””â”€â”€ LokaOrchestratorâ„¢ "Complex tasks. Minimum premium."
â”‚                          Task DAG decomposition â†’ parallel subtask execution
â”‚
â”œâ”€â”€ DECIDE
â”‚   â””â”€â”€ LokaLLMâ„¢        "The model that manages all the models."
â”‚                        Fine-tuned Phi-3 Mini â€” scores complexity, decomposes tasks
â”‚
â”œâ”€â”€ DISTRIBUTE
â”‚   â”œâ”€â”€ LokaMeshâ„¢       "Your devices. One intelligence."
â”‚   â”‚                    mDNS cluster discovery, WoL, node scheduling
â”‚   â””â”€â”€ LokaMobileâ„¢     "Private AI. In your pocket."
â”‚                        Battery-aware local AI on iOS/Android (React Native + llama.cpp)
â”‚
â””â”€â”€ COOPERATE
    â”œâ”€â”€ LokaCommonsâ„¢    "Your idle compute. Someone's breakthrough."
    â”‚                    Community compute cooperative
    â””â”€â”€ LokaSwapâ„¢       "Collective bargaining for the AI generation."
                         Token exchange + group purchasing layer
```

---

## 2. Current Architecture (v1.x MVP â€” Implemented âœ…)

### 2.1 Routing Pipeline

```
User Query
    â”‚
    â”œâ”€ Step 0: Memory Recall â”€â”€â”€â”€â”€â”€â”€ memory.enabled? â†’ prepend relevant context
    â”‚                                 MemoryManager.recall() â†’ TF-IDF similarity
    â”‚
    â”œâ”€ Step 1: PII Scan â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PIIScanner (email, IBAN, BSN/Elfproef,
    â”‚                                 phone, CC/Luhn, IP, names via NLP)
    â”‚                                 PII detected? â†’ force LOCAL
    â”‚
    â”œâ”€ Step 2: Token Estimate â”€â”€â”€â”€â”€â”€â”€ > 8,000 tokens? â†’ force LOCAL
    â”‚
    â”œâ”€ Step 2b: Search Augment â”€â”€â”€â”€â”€â”€ search.enabled? â†’ QueryExpander
    â”‚                                 â†’ ParallelRetriever (Brave + arXiv)
    â”‚                                 â†’ LocalFilter â†’ prepend web context
    â”‚
    â”œâ”€ Step 3: Complexity Score â”€â”€â”€â”€ TaskClassifier: 0.0â€“1.0
    â”‚    6 signals (weighted):
    â”‚    â”œâ”€â”€ tokenCountScore        15%  (normalised log of token count)
    â”‚    â”œâ”€â”€ questionComplexity     25%  (reasoning keywords: why, compare, analyse)
    â”‚    â”œâ”€â”€ technicalDensity       20%  (code blocks, stack traces, file paths)
    â”‚    â”œâ”€â”€ reasoningKeywords      20%  (because, therefore, justify, trade-off)
    â”‚    â”œâ”€â”€ cotIndicators          10%  (chain-of-thought markers)
    â”‚    â””â”€â”€ lengthBonus            10%  (sentence count signal)
    â”‚
    â”‚    score < 0.35  â†’ LOCAL  (Ollama, round-robin across cluster nodes)
    â”‚    score 0.35â€“0.65 â†’ SPECIALIST â†’ DELEGATED
    â”‚    score > 0.65  â†’ CLOUD  (fallback to specialist if no cloud API key)
    â”‚
    â”œâ”€ Step 4: Budget Check â”€â”€â”€â”€â”€â”€â”€ BudgetTracker (SQLite ~/.lokaflow/costs.db)
    â”‚    Daily + monthly EUR cap Â· warns at 80% Â· hard stop at limit
    â”‚    exceeded? â†’ downgrade to LOCAL
    â”‚
    â””â”€ Step 5: Execute + Log â”€â”€â”€â”€â”€â”€â”€ provider.stream() / provider.complete()
                                     DashboardTracker (metadata-only, no content)
                                     â†’ lokaflow-routing.log (rotates at 10MB)
```

### 2.2 Provider Tiers

```
LOCAL tier                   SPECIALIST tier              CLOUD tier
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OllamaProvider               GeminiProvider               ClaudeProvider  (Anthropic)
  baseUrl: localhost:11434     (GEMINI_API_KEY)            OpenAIProvider  (OpenAI)
  baseUrl: 192.168.x.x         or OllamaProvider          GeminiProvider  (fallback)
  round-robin, score-based                                 GroqProvider    (fast)
  cost: â‚¬0                    cost: â‚¬0.00069/1K           MistralProvider
                                                           TogetherProvider
                              â”Œâ”€â”€â”€â”€ Delegation â”€â”€â”€â”€â”      CohereProvider
                              â”‚ Specialist generatesâ”‚      PerplexityProvider
                              â”‚ JSON subtask plan   â”‚      AzureProvider
                              â”‚ Local workers exec  â”‚
                              â”‚ in parallel         â”‚      Priority auto-discovery:
                              â”‚ maxDepth = 2        â”‚      ANTHROPIC â†’ OPENAI â†’ GEMINI
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â†’ GROQ â†’ MISTRAL â†’ ...
```

### 2.3 Memory / RAG Pipeline (opt-in)

```
startup
  â””â”€â”€ ProfileStore.load() â”€â”€ SQLite ~/.lokaflow/profiles.db
        â””â”€â”€ customInstructions â†’ prepend as system message

per-turn
  â”œâ”€â”€ MemoryManager.recall()
  â”‚     â””â”€â”€ TfidfVectorizer.fit(all entries)
  â”‚           â†’ vectorize query
  â”‚           â†’ MemoryStore.similar() (cosine similarity)
  â”‚           â†’ prepend top-K as system message
  â”‚
  â””â”€â”€ MemoryManager.remember()
        â””â”€â”€ MemoryStore.add() â”€â”€ SQLite ~/.lokaflow/memory.db
              role: "user" | "assistant"
              content, vector (lazy â€” computed on next retrieval)
```

### 2.4 Deep Search Pipeline (opt-in)

```
query
  â””â”€â”€ QueryExpander.expand()
        â””â”€â”€ localProvider.complete() â†’ JSON { queries: [3 sub-queries] }
              â†“ fallback on error: [original query]

      ParallelRetriever.retrieve()
        â”œâ”€â”€ BraveSource  (BRAVE_API_KEY, 2000/month free)
        â””â”€â”€ ArxivSource  (no key, activates on research keywords)
            â†’ URL dedup â†’ SearchResult[]

      LocalFilter.filter()
        â””â”€â”€ localProvider.complete() â†’ { scores: [{ index, score }] }
            â†’ sort desc â†’ slice top-N
```

### 2.5 File Layout (current)

```
lokaflow/                          â† monorepo root (single package for MVP)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ types.ts                   Message, LLMResponse, RoutingDecision, LokaFlowConfig
â”‚   â”œâ”€â”€ exceptions.ts              Typed error hierarchy (6 error classes)
â”‚   â”œâ”€â”€ config.ts                  Zod YAML loader (3-path search, snake_caseâ†’camelCase)
â”‚   â”œâ”€â”€ index.ts                   Public package entry point
â”‚   â”œâ”€â”€ version.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ router/
â”‚   â”‚   â”œâ”€â”€ router.ts              Core 5-step pipeline + Step 0 + 2b + delegation
â”‚   â”‚   â”œâ”€â”€ classifier.ts          6-signal complexity scorer
â”‚   â”‚   â”œâ”€â”€ piiScanner.ts          Regex + compromise NLP
â”‚   â”‚   â”œâ”€â”€ budget.ts              SQLite cost tracker
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ providers/                 11 providers â€” all extend BaseProvider
â”‚   â”‚   â”œâ”€â”€ base.ts
â”‚   â”‚   â”œâ”€â”€ local.ts               Ollama
â”‚   â”‚   â”œâ”€â”€ claude.ts, openai.ts, gemini.ts, groq.ts
â”‚   â”‚   â”œâ”€â”€ mistral.ts, together.ts, perplexity.ts
â”‚   â”‚   â”œâ”€â”€ azure.ts, cohere.ts
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ search/                    Deep search pipeline (opt-in)
â”‚   â”‚   â”œâ”€â”€ engine.ts              SearchEngine orchestrator
â”‚   â”‚   â”œâ”€â”€ expander.ts            QueryExpander
â”‚   â”‚   â”œâ”€â”€ retriever.ts           ParallelRetriever
â”‚   â”‚   â”œâ”€â”€ filter.ts              LocalFilter
â”‚   â”‚   â”œâ”€â”€ sources/
â”‚   â”‚   â”‚   â”œâ”€â”€ brave.ts           BraveSource
â”‚   â”‚   â”‚   â””â”€â”€ arxiv.ts           ArxivSource
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/                    Memory + RAG pipeline (opt-in)
â”‚   â”‚   â”œâ”€â”€ store.ts               MemoryStore (SQLite + cosine similarity)
â”‚   â”‚   â”œâ”€â”€ profile.ts             ProfileStore (user prefs + customInstructions)
â”‚   â”‚   â”œâ”€â”€ rag.ts                 TfidfVectorizer, RagRetriever, MemoryManager
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â”œâ”€â”€ index.ts               lokaflow CLI (commander)
â”‚   â”‚   â”œâ”€â”€ chat.ts                Interactive chat + streaming + auto cloud discovery
â”‚   â”‚   â”œâ”€â”€ cost.ts                Cost report command
â”‚   â”‚   â””â”€â”€ supporters.ts          GitHub Sponsors list (24h cache)
â”‚   â”‚
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â”œâ”€â”€ tracker.ts             SQLite metadata logger (no content)
â”‚   â”‚   â””â”€â”€ report.ts              Cost + savings report formatter
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ security.ts            maskKey(), envVar(), requireEnvVar()
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                      42 + 17 + 27 = 86 test cases (Vitest, no network)
â”‚   â”‚   â”œâ”€â”€ classifier.test.ts     12 cases
â”‚   â”‚   â”œâ”€â”€ piiScanner.test.ts     14 cases
â”‚   â”‚   â”œâ”€â”€ budget.test.ts         8 cases
â”‚   â”‚   â”œâ”€â”€ router.test.ts         8 cases
â”‚   â”‚   â”œâ”€â”€ search.test.ts         17 cases (fully mocked)
â”‚   â”‚   â””â”€â”€ memory.test.ts         27 cases (in-memory SQLite)
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ local.test.ts          requires live Ollama
â”‚   â”‚   â””â”€â”€ pipeline.test.ts
â”‚   â””â”€â”€ fixtures/
â”‚
â”œâ”€â”€ impl/                          V2 design docs (read-only references)
â”‚   â”œâ”€â”€ CLAUDE_orchestrator.md    LokaOrchestrator DAG decomposition
â”‚   â”œâ”€â”€ CLAUDE_mesh.md            LokaMesh cluster
â”‚   â”œâ”€â”€ CLAUDE_root_v2.md         Full monorepo V2 vision
â”‚   â”œâ”€â”€ CLAUDE_audit.md           LokaAudit
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ lokaflow.yaml                  Active config (git-ignored)
    config/lokaflow.example.yaml   Reference with all defaults
```

---

## 3. V2 Target Architecture

### 3.1 Monorepo Layout (V2)

```
lokaflow/
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ core/                â† current src/ â†’ moved here as @lokaflow/core
â”‚   â”‚   â””â”€â”€ (router, providers, types, search, memory)
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                 â† @lokaflow/api â€” REST + OpenAI-compatible proxy â† NEXT
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ server.ts         Fastify server on :4141
â”‚   â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chat.ts       POST /v1/chat/completions (OpenAI-compat)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ route.ts      POST /v1/route (routing decision + explain)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ cost.ts       GET  /v1/cost
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ health.ts     GET  /v1/health
â”‚   â”‚   â”‚   â””â”€â”€ middleware/
â”‚   â”‚   â”‚       â”œâ”€â”€ auth.ts       API key auth (optional, local-by-default)
â”‚   â”‚   â”‚       â””â”€â”€ cors.ts       CORS for web UI
â”‚   â”‚
â”‚   â”œâ”€â”€ mesh/                â† @lokaflow/mesh / "lokamesh" npm
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ discovery/        MdnsDiscovery, NodeRegistry
â”‚   â”‚   â”‚   â”œâ”€â”€ scheduler/        MeshScheduler, PriorityTaskQueue
â”‚   â”‚   â”‚   â”œâ”€â”€ executor/         RemoteExecutor, NodeHttpClient
â”‚   â”‚   â”‚   â”œâ”€â”€ power/            WolSender, SleepStateMachine, PowerMonitor
â”‚   â”‚   â”‚   â””â”€â”€ green/            ElectricityMapsClient, GreenReport
â”‚   â”‚
â”‚   â”œâ”€â”€ orchestrator/        â† @lokaflow/orchestrator
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ complexity/       ComplexityMeasurer, 6 dimension scorers
â”‚   â”‚   â”‚   â”œâ”€â”€ decomposer/       TaskDecomposer, TaskGraph DAG, DecompositionGate
â”‚   â”‚   â”‚   â”œâ”€â”€ models/           ModelCapabilityRegistry, ModelSelector
â”‚   â”‚   â”‚   â”œâ”€â”€ pipeline/         Planâ†’Executeâ†’Verifyâ†’Assemble stages
â”‚   â”‚   â”‚   â”œâ”€â”€ budget/           TokenBudgetAllocator, enforcer
â”‚   â”‚   â”‚   â””â”€â”€ subscription/     SubscriptionMaximiser
â”‚   â”‚
â”‚   â”œâ”€â”€ lokallm/             â† @lokaflow/lokallm (fine-tuned Phi-3 Mini INT4)
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ inference/        InferenceEngine (llama.cpp GGUF)
â”‚   â”‚   â”‚   â”œâ”€â”€ scoring/          ComplexityScorer, HeuristicScorer
â”‚   â”‚   â”‚   â””â”€â”€ learning/         PersonalAdapterTrainer (nightly LoRA)
â”‚   â”‚
â”‚   â””â”€â”€ audit/               â† "lokaaudit" npm (MIT licensed, standalone)
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ parsers/          Claude, ChatGPT, Gemini export parsers
â”‚       â”‚   â”œâ”€â”€ tokeniser/        CL100k (exact), Gemini (approx)
â”‚       â”‚   â”œâ”€â”€ pricing/          PricingTable (verified monthly)
â”‚       â”‚   â””â”€â”€ report/           AuditResult, CLI + HTML formatters
â”‚       â””â”€â”€ web/                  Browser WASM UI (no server)
â”‚
â””â”€â”€ apps/
    â”œâ”€â”€ web/                 â† Web UI (Next.js) â€” dashboard + chat interface
    â””â”€â”€ mobile/              â† LokaMobile (React Native + Expo)
```

### 3.2 REST API Layer (packages/api) â€” V2.1

```
POST /v1/chat/completions    â† OpenAI-compatible (drop-in for any app)
  body: { model, messages, stream }
  â†’ Router.route() â†’ provider.stream()
  â†’ SSE stream or JSON response

POST /v1/route               â† routing decision (explain mode)
  body: { messages }
  â†’ Router.route() â†’ RoutingDecision JSON
  { tier, model, reason, complexityScore, trace, costEur }

GET  /v1/cost                â† cost dashboard data
  â†’ BudgetTracker.summary() â†’ { today, month, total, savings }

GET  /v1/health              â† provider health status
  â†’ each provider.healthCheck() â†’ { local: OK, specialist: OK, cloud: OK }

GET  /v1/models              â† available models + routing config
```

### 3.3 LokaMesh Integration (packages/mesh) â€” V2.2

```
lokanet.yaml                 â† cluster config (git-ignored, separate from lokaflow.yaml)
nodes:
  - id: mac-mini-m2          always_on: true   ip: 192.168.2.65
  - id: macbook-air-m4       orchestrator: true
  - id: desktop-i5           storage_hub: true  wol_mac: xx:xx:xx:xx:xx:xx

MdnsDiscovery â”€â”€â”€ announces this node on LAN every 30s
              â””â”€â”€ scans for _lokaflow._tcp.local â†’ NodeRegistry

MeshScheduler.selectNode(task):
  candidates = online nodes with required model + RAM + battery OK + thermal OK
  score = tokensPerSecÃ—0.40 + alwaysOnBonus - batteryStressÃ—0.20 - queuePenalty
  â†’ highest score wins

RemoteExecutor â†’ REST to selected node's Ollama API â†’ stream back

SleepStateMachine:
  ONLINE â†’ (idle 15min) â†’ LIGHT_SLEEP â†’ (idle 30min) â†’ DEEP_SLEEP
  WoL magic packet â†’ WAKING â†’ (boot 30â€“90s) â†’ ONLINE
```

### 3.4 LokaOrchestrator Pipeline â€” V2.3

```
Complex task (score > 0.65)
    â”‚
    â–¼ LokaLLM.decompose()  < 200ms, local, free
    TaskGraph (DAG, max 8 subtasks, max depth 3)
    â”‚
    â–¼ DecompositionGate
    latencyOverhead < 15% AND tokenSaving > 20% AND costSaving > 0 ?
    YES â†’ orchestrate   |   NO â†’ direct LokaRoute
    â”‚
    â”œâ”€ STAGE 1: PLAN  (LOCAL_STANDARD, Mistral 7B)
    â”‚   â†’ PlanDocument: scaffold, section needs, token budgets
    â”‚
    â”œâ”€ STAGE 2: EXECUTE (parallel, respects DAG edges)
    â”‚   Each subtask â†’ cheapest capable tier:
    â”‚   0.00â€“0.30 â†’ LOCAL_NANO   (TinyLlama 1.1B)
    â”‚   0.30â€“0.55 â†’ LOCAL_STANDARD (Mistral 7B)
    â”‚   0.55â€“0.68 â†’ LOCAL_LARGE  (Qwen 72B, if available)
    â”‚   0.50â€“0.72 â†’ CLOUD_LIGHT  (Claude Haiku / Gemini Flash)
    â”‚   0.65â€“0.87 â†’ CLOUD_STANDARD (Claude Sonnet / GPT-4o)
    â”‚   0.83â€“1.00 â†’ CLOUD_PREMIUM (Claude Opus / GPT-5.2 Thinking)
    â”‚
    â”œâ”€ STAGE 3: VERIFY (optional, LOCAL_STANDARD or CLOUD_LIGHT)
    â”‚   Precision dimension > 0.70? â†’ consistency + completeness check
    â”‚   Gaps found? â†’ targeted re-execution of gap subtask only
    â”‚
    â””â”€ STAGE 4: ASSEMBLE (LOCAL_NANO, always free)
        Merge subtask outputs â†’ consistent formatting â†’ final response

Result: 2/6 subtasks need cloud. Token reduction: 60%. Latency: 40% faster.
```

### 3.5 LokaAudit (packages/audit) â€” V2.4

```
CLI: lokaaudit conversations.json
Web: browser WASM (zero server, zero data upload)

AutoDetectParser â†’ ClaudeExportParser / ChatGPTExportParser / GeminiExportParser
    â†’ ParsedExport (normalised schema)

CL100kTokeniser (exact) / GeminiTokeniser (chars/4 Â±15%)
    â†’ token counts per conversation

CostCalculator
    actualCostEur   = tokens Ã— API rates (updated monthly, source URLs required)
    subscriptionEur = â‚¬20.00 (Claude Pro) | â‚¬20.00 (ChatGPT Plus)
    utilisationRate = actualCost / subscriptionCost Ã— 100
    overpayEur      = subscriptionCost - actualCostEur

LocalQueryClassifier â†’ localEligiblePercent (trivial + moderate)

Output:
  CLI: terminal gauge display
  HTML: self-contained shareable file
  CTA: https://lokaflow.io?saving=XX&ref=audit
```

---

## 4. Data Flow â€” Privacy Guarantees

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NEVER leaves device:                                          â”‚
â”‚  â€¢ Raw query content                                          â”‚
â”‚  â€¢ Conversation history (memory store)                        â”‚
â”‚  â€¢ User profile (custom instructions, language, topics)       â”‚
â”‚  â€¢ PII â€” routed to LOCAL before any API call                  â”‚
â”‚  â€¢ LokaAudit export data (processed in memory, then discarded)â”‚
â”‚  â€¢ LokaLLM meta-decisions (decomposition, complexity scoring) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Logged locally only (metadata, no content):                   â”‚
â”‚  â€¢ model name, tier, latency, cost, routing reason            â”‚
â”‚  â€¢ token counts (no tokens themselves)                        â”‚
â”‚  â€¢ â†’ ~/.lokaflow/costs.db, lokaflow-routing.log (rotates 10MB)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Sent to cloud only (when cloud tier is selected):             â”‚
â”‚  â€¢ Query content after PII scan passes                        â”‚
â”‚  â€¢ No session IDs, no account data, no routing metadata       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. V2 Build Order â€” Priority 5

| Step | Feature | Package | Status | Prerequisite |
|---|---|---|---|---|
| V2.1 | **REST API** (OpenAI-compatible proxy) | `packages/api/` | ğŸ”² Next | None |
| V2.2 | **LokaMesh** (cluster discovery + WoL) | `packages/mesh/` | ğŸ”² | None |
| V2.3 | **LokaOrchestrator** (task DAG) | `packages/orchestrator/` | ğŸ”² | REST API |
| V2.4 | **LokaAudit** (subscription analyser) | `packages/audit/` | ğŸ”² | None |
| V2.5 | **Web UI** (dashboard + chat) | `apps/web/` | ğŸ”² | REST API |
| V2.6 | **VS Code plugin** | `packages/vscode/` | ğŸ”² | REST API |
| V2.7 | **LokaLLM** (fine-tuned Phi-3) | `packages/lokallm/` | ğŸ”² | Training data from V2.3 |
| V2.8 | **LokaMobile** (iOS/Android) | `apps/mobile/` | ğŸ”² | LokaMesh |

---

## 6. Configuration Reference

### lokaflow.yaml (current)

```yaml
local:
  base_urls: ["http://localhost:11434", "http://192.168.2.65:11434"]
  default_model: "qwen2.5-coder:7b"
  timeout_seconds: 120

router:
  specialist_provider: gemini          # gemini | ollama | openai
  specialist_model: "gemini-2.0-flash"
  complexity_local_threshold: 0.35
  complexity_cloud_threshold: 0.65
  max_local_tokens: 8000
  fallback_to_local: true

cloud:
  claude_model: "claude-sonnet-4-20250514"
  openai_model: "gpt-4o"
  gemini_model: "gemini-2.0-flash"
  groq_model: "llama-3.3-70b-versatile"

budget:
  daily_limit_eur: 2.00
  monthly_limit_eur: 20.00
  warn_at_percent: 80

search:
  enabled: false        # opt-in â€” enable with BRAVE_API_KEY
  brave_enabled: true
  arxiv_enabled: true
  max_results: 5
  filter_threshold: 5.0

memory:
  enabled: false        # opt-in
  top_k: 4
  session_id: "default"
```

### lokanet.yaml (V2 â€” LokaMesh)

```yaml
nodes:
  - id: mac-mini-m2
    role: always_on
    ip: 192.168.2.65
    port: 11434
    models: ["qwen2.5-coder:7b", "mistral:7b"]
    ram_gb: 8
    inference_watts: 10
    gpu_acceleration: true      # Apple Silicon Metal
    always_on: true

  - id: macbook-air-m4
    role: orchestrator
    ip: auto                    # auto-discovered via mDNS
    models: ["qwen2.5-coder:7b", "phi3:mini"]
    ram_gb: 16
    sleep:
      enabled: true
      idle_minutes: 15
      wol: false                 # no WoL on laptop (lid close)

  - id: desktop-i5
    role: storage
    ip: auto
    models: []                   # no inference â€” storage only
    ram_gb: 32
    mac_address: "xx:xx:xx:xx:xx:xx"
    sleep:
      enabled: true
      idle_minutes: 30
      wol: true                  # WoL for burst demand
```

---

## 7. Complexity Score â€” Quick Reference

| Score | Tier | Provider | Example queries |
|---|---|---|---|
| 0.00â€“0.35 | LOCAL | Ollama (round-robin) | "What is 2+2?", "Format this JSON" |
| 0.35â€“0.65 | SPECIALIST â†’ DELEGATED | Gemini (planner) + Local (workers) | "Review this function", "Summarise this doc" |
| 0.65â€“1.00 | CLOUD | Gemini / Claude / OpenAI | "Design an auth architecture", "DORA compliance analysis" |

**Fallback chain (cloud unavailable / no API key):**
`CLOUD â†’ SPECIALIST â†’ LOCAL` â€” always graceful, never crashes.

---

## 8. Cost Model

| Provider | Input (EUR/1K) | Output (EUR/1K) | Tier |
|---|---|---|---|
| Ollama (local) | â‚¬0.00 | â‚¬0.00 | LOCAL |
| Gemini 2.0 Flash | â‚¬0.00069 | â‚¬0.00276 | SPECIALIST/CLOUD |
| Groq Llama 70B | â‚¬0.00053 | â‚¬0.00071 | CLOUD |
| Claude Sonnet | â‚¬0.0028 | â‚¬0.014 | CLOUD |
| OpenAI GPT-4o | â‚¬0.0046 | â‚¬0.0138 | CLOUD |
| Claude Opus | â‚¬0.015 | â‚¬0.075 | CLOUD_PREMIUM |

**V2 blended saving target:**
```
total_saving% = local_route%(60â€“70%)
              + orchestrator_reduction%(30â€“65% of cloud queries)
              + subscription_maximiser%(35â€“60% of premium tokens)
= 80â€“95% vs naive all-cloud approach
```

---

*Â© 2026 LearnHubPlay BV Â· LokaFlowâ„¢ Â· BUSL 1.1 Â· lokaflow.io*
