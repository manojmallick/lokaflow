# LokaFlow™ — Environment Variables
# © 2026 LearnHubPlay BV
#
# Copy this file to .env and fill in your values.
# NEVER commit .env to git — it is already in .gitignore.
#
# cp .env.example .env

# ──────────────────────────────────────────────────────
# CLOUD MODEL API KEYS
# Only used when the router escalates to cloud models.
# Leave blank to disable that provider.
# ──────────────────────────────────────────────────────

# Anthropic Claude (claude-3-5-sonnet, claude-3-5-haiku, claude-opus-4)
# Get key: https://console.anthropic.com
ANTHROPIC_API_KEY=

# OpenAI (gpt-4o, gpt-4o-mini, gpt-4-turbo, o1, o3-mini)
# Get key: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Google Gemini (gemini-2.0-flash, gemini-1.5-pro, gemini-1.5-flash)
# Get key: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=

# Groq — ultra-fast inference (llama-3.3-70b-versatile, mixtral-8x7b, gemma2-9b)
# Get key: https://console.groq.com/keys
GROQ_API_KEY=

# Mistral AI (mistral-large-latest, mistral-small-latest, codestral-latest)
# Get key: https://console.mistral.ai
MISTRAL_API_KEY=

# Cohere (command-r-plus, command-r, command-light)
# Get key: https://dashboard.cohere.com/api-keys
COHERE_API_KEY=

# Together AI (llama-3-70b, qwen-2.5-72b, deepseek-v3, etc.) — open models in cloud
# Get key: https://api.together.ai
TOGETHER_API_KEY=

# Perplexity (sonar-pro, sonar, sonar-reasoning) — search-augmented LLM
# Get key: https://www.perplexity.ai/settings/api
PERPLEXITY_API_KEY=

# Azure OpenAI (uses same models as OpenAI but hosted on Azure)
# Get from: https://portal.azure.com
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=
# AZURE_OPENAI_DEPLOYMENT=gpt-4o

# ──────────────────────────────────────────────────────
# LOCAL MODEL CONFIGURATION (Ollama)
# ──────────────────────────────────────────────────────

# Ollama server URL (default: local)
OLLAMA_HOST=http://localhost:11434

# Default local model for general tasks
LOKAFLOW_LOCAL_MODEL=llama3.3:70b

# Default local model for code tasks
LOKAFLOW_CODE_MODEL=deepseek-coder:33b

# Default local model for vision tasks
LOKAFLOW_VISION_MODEL=moondream:latest

# ──────────────────────────────────────────────────────
# ROUTING CONFIGURATION
# ──────────────────────────────────────────────────────

# Token threshold above which router considers cloud escalation
LOKAFLOW_CLOUD_THRESHOLD_TOKENS=2000

# Force all tasks local (never call cloud APIs) — true | false
LOKAFLOW_LOCAL_ONLY=false

# Enable PII scanning before cloud escalation — true | false
LOKAFLOW_PII_SCAN=true

# ──────────────────────────────────────────────────────
# SEARCH (optional)
# ──────────────────────────────────────────────────────

# Brave Search API key (free tier available at brave.com/search/api)
BRAVE_SEARCH_API_KEY=

# SearXNG self-hosted instance URL (alternative to Brave)
# SEARXNG_URL=http://localhost:8080

# ──────────────────────────────────────────────────────
# LOKAFLOW SERVER (if running as a local API server)
# ──────────────────────────────────────────────────────

LOKAFLOW_HOST=127.0.0.1
LOKAFLOW_PORT=7433

# ──────────────────────────────────────────────────────
# LOGGING
# ──────────────────────────────────────────────────────

# Log level: debug | info | warn | error
LOKAFLOW_LOG_LEVEL=info

# Log routing decisions (which model was chosen and why)
LOKAFLOW_LOG_ROUTING=true
